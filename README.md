## Hi there 👋

<!--
**kamyarothmanhamad/kamyarothmanhamad** is a ✨ _special_ ✨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- 🔭 I’m currently working on ...
- 🌱 I’m currently learning ...
- 👯 I’m looking to collaborate on ...
- 🤔 I’m looking for help with ...
- 💬 Ask me about ...
- 📫 How to reach me: ...
- 😄 Pronouns: ...
- ⚡ Fun fact: ...
-->


<!--
  ⚠️ Rename this file to README.md
  ⚠️ This repo’s name must exactly match your GitHub username to display this on your profile :contentReference[oaicite:3]{index=3}.
-->

# Hi there 👋, I’m Kamyar

**🔭 I’m currently a 2nd‑year PhD student in 3D Computer Vision** at **CSU**, focusing on **3D human parsing** and **scene understanding**.


**🌱 I’m currently learning** advanced neural rendering techniques and geometric deep learning for deformable object modeling :contentReference[oaicite:5]{index=5}.

---

- 🎓 **Position:** 2nd‑year PhD student, 3D Computer Vision @ CSU  
- 🌐 **Affiliation:** Department of Automation, CSU  
- 💡 **Current Projects:**  
  - **3D Human Parsing:** Semantic and instance‑level decomposition of human shapes :contentReference[oaicite:10]{index=10}  
  - **Scene Understanding:** 3D semantic and instance segmentation for indoor/outdoor environments :contentReference[oaicite:11]{index=11}  
- 💬 **Pronouns:** He/Him
  
---

## 🔍 Research Interests  
- **Point Cloud Processing:** Denoising, completion, and enhancement of raw LiDAR/RGB‑D data :contentReference[oaicite:12]{index=12}  
- **Geometric Deep Learning:** Graph neural networks and mesh‑based representations :contentReference[oaicite:13]{index=13}  
- **Topological Deep Learning:** Extracting and leveraging topological features from point clouds :contentReference[oaicite:14]{index=14}  
- **Vision–Language Models for 3D:** Open‑vocabulary scene graph prediction and multimodal embeddings :contentReference[oaicite:15]{index=15}  
- **3D Gaussian Splatting:** Photorealistic volumetric capture using Gaussian blobs :contentReference[oaicite:16]{index=16}  
- **Neural Radiance Fields (NeRFs):** Implicit volumetric scene modeling and rendering :contentReference[oaicite:17]{index=17}  
- **Differentiable Rendering:** End‑to‑end trainable rendering pipelines for 3D reconstruction :contentReference[oaicite:18]{index=18}  
- **SLAM with Deep Learning:** Robust visual odometry and mapping via learned features :contentReference[oaicite:19]{index=19}  
- **Self‑Supervised 3D Representations:** Contrastive and generative pre‑training on 3D data :contentReference[oaicite:20]{index=20}  
- **3D Semantic & Panoptic Segmentation:** Instance‑aware scene parsing at scale   
- **4D Dynamic Scene Modeling:** Temporal evolution of geometry for dynamic environments :contentReference[oaicite:21]{index=21}  


---

## 🚀 Projects  
<!-- For each project, link to the repo and include a one‑sentence description. -->
- [**NeRF‑3D‑Recon**](https://github.com/yourname/nerf-3d-recon): Implementation of Neural Radiance Fields for dynamic scene reconstruction with customizable control over geometry and appearance :contentReference[oaicite:7]{index=7}  
- [**Mesh‑Graph‑CNN**](https://github.com/yourname/mesh-graph-cnn): Geometric deep network for point‑cloud segmentation and classification on benchmark datasets  
- [**SLAM‑Benchmark**](https://github.com/yourname/slam-benchmark): Comparative study and evaluation suite for state‑of‑the‑art SLAM approaches  
- [**3D‑Pose‑Estimator**](https://github.com/yourname/3d-pose-estimator): Real‑time human pose estimation and skeleton reconstruction from monocular video :contentReference[oaicite:8]{index=8}  

---

## 📚 Publications  
- **Your Name**, Co‑author. “Title of Your ICCV/CVPR Paper,” *Proceedings of CVPR 2024*, pp. 1234–1243.  
- **Your Name**, Co‑author. “Title of Your ECCV/ICCV Paper,” *Proceedings of ICCV 2023*, pp. 567–578.  

---

## 🛠️ Skills  
<details>
<summary>Click to expand</summary>

- **Languages:** Python, C++, CUDA  
- **Frameworks:** PyTorch, TensorFlow, Open3D  
- **Tools:** Git, Docker, ROS  
- **Concepts:** Photogrammetry, SLAM, Neural Rendering, Geometric DL  

</details>  
*Tip:* Use icons and badges to make this section visually appealing; see [Simple Icons](https://simpleicons.org/) for SVG badges :contentReference[oaicite:9]{index=9}.

---

## 📫 Contact Me  
- 📧 Email: [your.email@university.edu]  
- 🔗 LinkedIn: [linkedin.com/in/yourprofile]  
- 🐦 Twitter: [@yourhandle]  

---

## 🔗 Quick Links  
- 📄 [Curriculum Vitae](https://your‑university.edu/yourcv.pdf)  
- 📊 [GitHub Stats](https://github.com/yourname/github-readme-stats)  

---

## Tips & Best Practices  
1. **Keep it concise:** Aim for 200–300 lines—readers skim; make each word count :contentReference[oaicite:10]{index=10}.  
2. **Use sections & emojis:** Improves scannability and conveys personality :contentReference[oaicite:11]{index=11}.  
3. **Show, don’t tell:** Include GIFs/screenshots of your demos, and link to live apps if available :contentReference[oaicite:12]{index=12}.  
4. **Keep up to date:** Regularly add new publications and projects as your PhD progresses.  
